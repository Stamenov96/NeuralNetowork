package org.exampl.neuralnet;

import org.exampl.neuralnet.Helpers;

class NeuralNetwork {
	private int numInput;
	private int numHidden;
	private int numOutput;

	private double[] inputs;
	private double[][] ihWeights; // input-to-hidden
	private double[] ihSums;
	private double[] ihBiases;
	private double[] ihOutputs;

	private double[][] hoWeights; // hidden-to-output
	private double[] hoSums;
	private double[] hoBiases;
	private double[] outputs;

	private double[] oGrads; // output gradients for back-propagation
	private double[] hGrads; // hidden gradients for back-propagation

	private double[][] ihPrevWeightsDelta; // for momentum with back-propagation
	private double[] ihPrevBiasesDelta;

	private double[][] hoPrevWeightsDelta;
	private double[] hoPrevBiasesDelta;

	public NeuralNetwork(int numInput, int numHidden, int numOutput)
    {
      this.numInput = numInput;
      this.numHidden = numHidden;
      this.numOutput = numOutput;

      inputs = new double[numInput];
      ihWeights = Helpers.MakeMatrix(numInput, numHidden);
      ihSums = new double[numHidden];
      ihBiases = new double[numHidden];
      ihOutputs = new double[numHidden];
      hoWeights = Helpers.MakeMatrix(numHidden, numOutput);
      hoSums = new double[numOutput];
      hoBiases = new double[numOutput];
      outputs = new double[numOutput];

      oGrads = new double[numOutput];
      hGrads = new double[numHidden];

      ihPrevWeightsDelta = Helpers.MakeMatrix(numInput, numHidden);
      ihPrevBiasesDelta = new double[numHidden];
      hoPrevWeightsDelta = Helpers.MakeMatrix(numHidden, numOutput);
      hoPrevBiasesDelta = new double[numOutput];
    }


	@SuppressWarnings("unused")
	public void SetWeights(/*double[] weights*/) throws Exception {
		int numWeights = (numInput * numHidden) + (numHidden * numOutput)
				+ numHidden + numOutput;
		/*if (weights.length != numWeights)
			throw new Exception(
					"The weights array length: "
							+ weights.length
							+ " does not match the total number of weights and biases: "
							+ numWeights);*/
		
		double[] ihBiases = new double[] { -2.0, -6.0, -1.0, -7.0 };
		double[] ihWeightsW = new double[] { 0.1, 0.2, 0.3, 0.4, 0.5,
				0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2 };
		double[] hoBiases = new double[] {-2.5 , -5.0 };
		double[] hoWeightsW = new double[] {1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0};
		
		
	
		
//	int k = 0; // points into weights param
		int k=0;
		for (int i = 0; i < numInput; ++i)
			for (int j = 0; j < numHidden; ++j)
				ihWeights[i][j] = ihWeightsW[k++];
		
		
		k=0;
		for (int i = 0; i < numHidden; ++i)
			for (int j = 0; j < numOutput; ++j)
				hoWeights[i][j] = hoWeightsW[k++];
		
		/*	
			//System.out.println("IHWeights -------");
			//Helpers.ShowMatrix(ihWeights, numInput);
				
		
		for (int i = 0; i < numHidden; ++i)
			ihBiases[i] = weights[k++];
		//System.out.println("IHBIASES -------");
		//	Helpers.ShowVector(ihBiases);
		

		System.out.println("hoWeights");
		Helpers.ShowMatrix(hoWeights, numHidden);
		for (int i = 0; i < numOutput; ++i)
			hoBiases[i] = weights[k++];
		//System.out.println("hoBiases--------");
		//Helpers.ShowVector(hoBiases);*/

	}
	
	

	public double[] ComputeOutputs(double[] xValues) throws Exception {
		if (xValues.length != numInput)
			throw new Exception("Inputs array length " + inputs.length
					+ " does not match NN numInput value " + numInput);

		for (int i = 0; i < numHidden; ++i)
			ihSums[i] = 0.0;
		
		for (int i = 0; i < numOutput; ++i)
			hoSums[i] = 0.0;

		for (int i = 0; i < xValues.length; ++i)
			// copy x-values to inputs
			this.inputs[i] = xValues[i];
		
		// System.out.println("Inputs:");
		// Helpers.ShowVector(this.inputs);

		// System.out.println("input-to-hidden weights:");
		// Helpers.ShowMatrix(this.ihWeights, -1);

		for (int j = 0; j < numHidden; ++j)
			// compute input-to-hidden weighted sums
			for (int i = 0; i < numInput; ++i)
				ihSums[j] += this.inputs[i] * ihWeights[i][j];

		// System.out.println("input-to-hidden sums:");
		// Helpers.ShowVector(this.ihSums);

		// System.out.println("input-to-hidden biases:");
		// Helpers.ShowVector(ihBiases);
		System.out.println("BEFORE:");
		Helpers.ShowVector(ihSums);
		
		for (int i = 0; i < numHidden; ++i)
			// add biases to input-to-hidden sums
			ihSums[i] += ihBiases[i];
		
		System.out.println("\ninput-to-hidden sums after adding i-h biases:");
		Helpers.ShowVector(this.ihSums);

		for (int i = 0; i < numHidden; ++i)
			// determine input-to-hidden output
			// ihOutputs[i] = StepFunction(ihSums[i]); // step function
			ihOutputs[i] = SigmoidFunction(ihSums[i]);

		// System.out.println("\ninput-to-hidden outputs after sigmoid:");
		// Helpers.ShowVector(this.ihOutputs);

		// System.out.println("hidden-to-output weights:");
		// Helpers.ShowMatrix(hoWeights, -1);

		for (int j = 0; j < numOutput; ++j)
			// compute hidden-to-output weighted sums
			for (int i = 0; i < numHidden; ++i)
				hoSums[j] += ihOutputs[i] * hoWeights[i][j];

		// System.out.println("hidden-to-output sums:");
		// Helpers.ShowVector(hoSums);

		// System.out.println("hidden-to-output biases:");
		// Helpers.ShowVector(this.hoBiases);

		for (int i = 0; i < numOutput; ++i)
			// add biases to input-to-hidden sums
			hoSums[i] += hoBiases[i];

		System.out.println("hidden-to-output sums after adding h-o biases:");
		Helpers.ShowVector(this.hoSums);

		for (int i = 0; i < numOutput; ++i)
			// determine hidden-to-output result
			this.outputs[i] = HyperTanFunction(hoSums[i]);

		double[] result = new double[numOutput];
		result = this.outputs;
		System.out.printf("NEW RESULTS: ",result);
		return result;
	} // ComputeOutputs

    @SuppressWarnings("unused")
	private static double StepFunction(double x) // an activation function that isn't compatible with back-propagation bcause it isn't differentiable
    {
      if (x > 0.0) return 1.0;
      else return 0.0;
    }
    public void UpdateWeights(double[] tValues, double eta, double alpha) throws Exception // update the weights and biases using back-propagation, with target values, eta (learning rate), alpha (momentum)
    {
      // assumes that SetWeights and ComputeOutputs have been called and so all the internal arrays and matrices have values (other than 0.0)
      if (tValues.length != numOutput)
        throw new Exception("target values not same length as output in UpdateWeights");

      // 1. compute output gradients
      for (int i = 0; i < oGrads.length; ++i)
      {
        double derivative = (1 - outputs[i]) * (1 + outputs[i]); // derivative of tanh
        oGrads[i] = derivative * (tValues[i] - outputs[i]);
      }

      // 2. compute hidden gradients
      for (int i = 0; i < hGrads.length; ++i)
      {
        double derivative = (1 - ihOutputs[i]) * ihOutputs[i]; // (1 / 1 + exp(-x))'  -- using output value of neuron
        double sum = 0.0;
        for (int j = 0; j < numOutput; ++j) // each hidden delta is the sum of numOutput terms
          sum += oGrads[j] * hoWeights[i][j]; // each downstream gradient * outgoing weight
        hGrads[i] = derivative * sum;
      }

      // 3. update input to hidden weights (gradients must be computed right-to-left but weights can be updated in any order
      for (int i = 0; i < ihWeights.length; ++i) // 0..2 (3)
      {
        for (int j = 0; j < ihWeights[0].length; ++j) // 0..3 (4)
        {
          double delta = eta * hGrads[j] * inputs[i]; // compute the new delta
          ihWeights[i][j] += delta; // update
          ihWeights[i][j] += alpha * ihPrevWeightsDelta[i][j]; // add momentum using previous delta. on first pass old value will be 0.0 but that's OK.
        }
      }

      // 3b. update input to hidden biases
      for (int i = 0; i < ihBiases.length; ++i)
      {
        double delta = eta * hGrads[i] * 1.0; // the 1.0 is the constant input for any bias; could leave out
        ihBiases[i] += delta;
        ihBiases[i] += alpha * ihPrevBiasesDelta[i];
      }

      // 4. update hidden to output weights
      for (int i = 0; i < hoWeights.length; ++i)  // 0..3 (4)
      {
        for (int j = 0; j < hoWeights[0].length; ++j) // 0..1 (2)
        {
          double delta = eta * oGrads[j] * ihOutputs[i];  // see above: ihOutputs are inputs to next layer
          hoWeights[i][j] += delta;
          hoWeights[i][j] += alpha * hoPrevWeightsDelta[i][j];
          hoPrevWeightsDelta[i][j] = delta;
        }
      }

      // 4b. update hidden to output biases
      for (int i = 0; i < hoBiases.length; ++i)
      {
        double delta = eta * oGrads[i] * 1.0;
        hoBiases[i] += delta;
        hoBiases[i] += alpha * hoPrevBiasesDelta[i];
        hoPrevBiasesDelta[i] = delta;
      }
    }

    public double[] GetWeights()
    {
      int numWeights = (numInput * numHidden) + (numHidden * numOutput) + numHidden + numOutput;
      double[] result = new double[numWeights];
      int k = 0;
      for (int i = 0; i < ihWeights.length; ++i)
        for (int j = 0; j < ihWeights[0].length; ++j)
          result[k++] = ihWeights[i][j];
      for (int i = 0; i < ihBiases.length; ++i)
        result[k++] = ihBiases[i];
      for (int i = 0; i < hoWeights.length; ++i)
        for (int j = 0; j < hoWeights[0].length; ++j)
          result[k++] = hoWeights[i][j];
      for (int i = 0; i < hoBiases.length; ++i)
        result[k++] = hoBiases[i];
      return result;
    }

	private double SigmoidFunction(double x) {
		if (x < -45.0)
			return 0.0;
		else if (x > 45.0)
			return 1.0;
		else
			return 1.0 / (1.0 + Math.exp(-x));
	}

	private double HyperTanFunction(double x) {
		if (x < -10.0)
			return -1.0;
		else if (x > 10.0)
			return 1.0;
		else
			return Math.tanh(x);
	}

} // class NeuralNetwork